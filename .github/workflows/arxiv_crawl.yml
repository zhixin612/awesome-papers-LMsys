name: Arxiv Paper Crawler

on:
  schedule:
    - cron: '0 0 */1 * *'  # Runs at UTC 00:00, every day. --> UTC+8 08:00
  workflow_dispatch:

permissions:
  contents: write
    
# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  crawl:
    name: Crawl and Update Data
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 pytz arxiv openai dotenv

      # Run the crawler script
      - name: Run crawler and update daily arxiv
        run: |
          python tools/main.py
        env:
          API_KEY: ${{ secrets.SILICONFLOW_API_KEY }}

      # Commit and push changes if any
      - name: Commit changes
        run: |
          git config --local user.name "zhixin612"
          git config --local user.email "zhao612@tju.edu.cn"
          git commit -a -m "Update daily arxiv papers" || echo "No changes to commit"
          git push
        env: 
         GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
